{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data\n",
    "\n",
    "> Class for loading, manipulating, and saving images and bounding box annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "from nbdev.showdoc import *\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from cv2 import rectangle\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PTBDataset(Dataset):\n",
    "    def __init__(self, root, annos, box_format, tfms = None, norm_chnls=None, ):\n",
    "        self.root = root\n",
    "        self.tfms = tfms\n",
    "        if tfms:\n",
    "            assert norm_chnls in [3,4], 'Improper channel stats for normalization'\n",
    "        self.norm_chnls = norm_chnls\n",
    "        self.coco = COCO(annos)\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "        assert box_format in ['coco', 'cntr_ofst',\n",
    "                              'cntr_ofst_frac',\n",
    "                              'corner_ofst_frac'], 'Improper box format'\n",
    "        self.box_format = box_format\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        coco = self.coco\n",
    "        img_id = self.ids[idx]\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        coco_annotation = coco.loadAnns(ann_ids)\n",
    "        path = coco.loadImgs(img_id)[0]['file_name']\n",
    "\n",
    "        # open input image and convert to np.ndarray\n",
    "        img = Image.open(os.path.join(self.root, path))\n",
    "        img = np.array(img, dtype = np.float32) / 255.\n",
    "        imgh, imgw = img.shape[:2]\n",
    "        \n",
    "        # 3-channel image transforms\n",
    "        if self.tfms and self.norm_chnls == 3:\n",
    "            img = self.tfms(\n",
    "                torch.as_tensor(\n",
    "                    img, dtype = torch.float32\n",
    "                ).permute(2,0,1))\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "\n",
    "        # new 4-channel array\n",
    "        img_4ch = np.zeros([imgh, imgw, 4], dtype = np.float32)\n",
    "        img_4ch[:,:,:3] = img\n",
    "        \n",
    "        # box coords form annotation\n",
    "        xmin, ymin, boxw, boxh = coco_annotation[0]['bbox']\n",
    "        \n",
    "        # Bounding boxes\n",
    "        if self.box_format == 'coco':\n",
    "            # Coco format: [xmin, ymin, width, height]\n",
    "            target = [xmin, ymin, boxw, boxh]\n",
    "            target = torch.as_tensor(target, dtype = torch.float32)\n",
    "        \n",
    "        else:\n",
    "            # convert box coords \n",
    "            target = self.convert_cords(xmin, ymin, boxw, \n",
    "                                        boxh, imgw, imgh,\n",
    "                                        self.box_format)\n",
    "            target = torch.as_tensor(target, dtype = torch.float32)\n",
    "            \n",
    "        # object prompt centers for 4th-channel image mask\n",
    "        xcntr, ycntr = coco_annotation[0]['center']\n",
    "        \n",
    "        # create center mask and change center value to 1\n",
    "        # np indexing [row, col] => [cntr_y, cntr_x]\n",
    "        cntr_mask = np.zeros([int(imgh),int(imgw)], dtype = np.float32)\n",
    "        cntr_mask[int(ycntr)][int(xcntr)] = 1\n",
    "        \n",
    "        # add mask to img as 4th channel\n",
    "        img_4ch[:,:,-1] = cntr_mask\n",
    "        img_4ch = torch.as_tensor(img_4ch, dtype = torch.float32)\n",
    "        \n",
    "        # re-order image sequence\n",
    "        # from: [w, h, c]\n",
    "        # to  : [c, w, h]\n",
    "        img_4ch = img_4ch.permute(2,0,1)\n",
    "        \n",
    "        # 4-channel image transforms\n",
    "        if self.tfms and self.norm_chnls == 4:\n",
    "            img_4ch = self.tfms(img_4ch)\n",
    "#             img = img.permute(1, 2, 0).numpy()\n",
    "            \n",
    "        return img_4ch, target\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def foo_bar():\n",
    "    Print('This is a test function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eff_loc",
   "language": "python",
   "name": "eff_loc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
