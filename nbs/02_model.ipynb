{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-requirement",
   "metadata": {},
   "source": [
    "# model\n",
    "\n",
    "> Class for EfficientLoc model loading, training, and exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.optim as opt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EfficientLoc():\n",
    "    \n",
    "    def __init__(self, version = 'efficientnet-b0', in_channels = 4, out_features = 4, export = False):\n",
    "        \"\"\"\n",
    "        EfficientLoc model class for loading, training, and exporting models\n",
    "        \"\"\"\n",
    "        \n",
    "        self.version = version\n",
    "        \n",
    "        \n",
    "#         self.inter_channels = versoin_dict([version])\n",
    "        # TODO\n",
    "        # check version is compliant\n",
    "        self.in_channels = in_channels\n",
    "        self.out_features = out_features\n",
    "        self.export = export\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.get_model(version = self.version, \n",
    "            in_channels = self.in_channels, out_features  = self.out_features)\n",
    "        \n",
    "    def get_model(self, version, in_channels, out_features):\n",
    "        \"\"\"\n",
    "        Adjusts efficient net model architecture for point-to-box data\n",
    "        \"\"\"\n",
    "\n",
    "        version_chnls = {\n",
    "            'efficientnet-b0': 1280,\n",
    "            'efficientnet-b1': 1280,\n",
    "            'efficientnet-b2': 1408,\n",
    "            'efficientnet-b3': 1536,\n",
    "            'efficientnet-b4': 1792\n",
    "#             'efficientnet-b5': 456\n",
    "#             'efficientnet-b6': 528\n",
    "#             'efficientnet-b7': 600\n",
    "#             'efficientnet-b8': 672\n",
    "#             'efficientnet-l2': 800\n",
    "        \n",
    "        }\n",
    "        \n",
    "        inter_channel = version_chnls[version]\n",
    "        \n",
    "        model = EfficientNet.from_pretrained(version, include_top = False)\n",
    "\n",
    "        # adjust in channels in conv stem\n",
    "        model._change_in_channels(in_channels)\n",
    "        \n",
    "#         if self.export:\n",
    "        model.set_swish(memory_efficient= (not self.export))\n",
    "            \n",
    "        model = torch.nn.Sequential(\n",
    "            model,\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(inter_channel, out_features),\n",
    "#             torch.nn.Linear(100, out_features),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True \n",
    "            \n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(f'Using {torch.cuda.device_count()} GPUs')\n",
    "            model = torch.nn.DataParallel(model)\n",
    "        \n",
    "        model.to(self.device)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, dataloaders, criterion, optimizer, num_epochs, ds_sizes, print_every = 100, scheduler=None):\n",
    "        \"\"\"\n",
    "        Training function for model\n",
    "        \n",
    "        **Params**\n",
    "        \n",
    "        loaders : dict of val/train DataLoaders\n",
    "        \n",
    "        criterion : loss function\n",
    "        \n",
    "        optimizer : training optimizer\n",
    "        \n",
    "        num_epochs : number of training epochs\n",
    "        \n",
    "        ds_sizes : dict of number of samples in \n",
    "        \n",
    "        print_every : batch_interval for intermediate loss printing\n",
    "        \n",
    "        scheduler : Optional learning rate scheduler\n",
    "        \"\"\"\n",
    "        train_start = time.time()\n",
    "        best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "        best_loss = 10000000.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                phase_start = time.time()\n",
    "                if phase == 'train':\n",
    "                    self.model.train()  \n",
    "                else:\n",
    "                    self.model.eval()   \n",
    "                \n",
    "                inter_loss = 0.\n",
    "                running_loss = 0.\n",
    "                batches_past = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    labels = labels.to(self.device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward, only track history in train phase\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = self.model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "                    inter_loss += loss.item()\n",
    "                    \n",
    "                    if (i+1) % print_every == 0:\n",
    "                        \n",
    "                        inter_loss = inter_loss / ((i+1-batches_past) * inputs.shape[0])\n",
    "                        print(f'Intermediate loss: {inter_loss:.6f}')\n",
    "                        inter_loss = 0.\n",
    "                        batches_past = i+1\n",
    "\n",
    "                if phase == 'train' and scheduler is not None:\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / ds_sizes[phase]\n",
    "\n",
    "                phase_duration = time.time() - phase_start\n",
    "                phase_duration = f'{(phase_duration // 60):.0f}m {(phase_duration % 60):.0f}s'\n",
    "                print('-' * 5)\n",
    "                print(f'{phase} Phase Duration: {phase_duration}  Average Loss: {epoch_loss:.6f} in ')\n",
    "                print('-' * 5)\n",
    "                \n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - train_start\n",
    "        print(f'Training complete in {(time_elapsed // 60):.0f}m {(time_elapsed % 60):.0f}s')\n",
    "        print(f'Best val Loss: {best_loss:.4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        self.model.load_state_dict(best_model_wts)\n",
    "              \n",
    "              \n",
    "    def save(self, dst, info = None):\n",
    "        \"\"\"Save model and optimizer state dict\n",
    "        \n",
    "        **Params**\n",
    "        \n",
    "        dst : destination file path including .pth file name\n",
    "        \n",
    "        info : Optional dictionary with model info\n",
    "        \n",
    "        \"\"\"\n",
    "        if info:\n",
    "            torch.save(info, dst)\n",
    "        else:\n",
    "            torch.save({\n",
    "                'base_arch' : self.version,\n",
    "                'model_state_dict' : self.model.state_dict(),\n",
    "            }, dst)\n",
    "            \n",
    "    def load(self, model_state_dict):\n",
    "        \"\"\"Load model weights from state-dict\"\"\"\n",
    "        self.model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-tooth",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f6c9b320964c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCIoU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"\"\"Complete IoU loss class\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#export\n",
    "class CIoU(torch.nn.Module):\n",
    "    \"\"\"Complete IoU loss class\"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super(CIoU, self).__init__()\n",
    "\n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        return self.ciou(input, target)\n",
    "#         return F.l1_loss(input, target, reduction=self.reduction)\n",
    "\n",
    "    def ciou(self, bboxes1, bboxes2):\n",
    "        bboxes1 = torch.sigmoid(bboxes1)\n",
    "        bboxes2 = torch.sigmoid(bboxes2)\n",
    "        rows = bboxes1.shape[0]\n",
    "        cols = bboxes2.shape[0]\n",
    "        cious = torch.zeros((rows, cols))\n",
    "        if rows * cols == 0:\n",
    "            return cious\n",
    "        exchange = False\n",
    "        if bboxes1.shape[0] > bboxes2.shape[0]:\n",
    "            bboxes1, bboxes2 = bboxes2, bboxes1\n",
    "            cious = torch.zeros((cols, rows))\n",
    "            exchange = True\n",
    "        w1 = torch.exp(bboxes1[:, 2])\n",
    "        h1 = torch.exp(bboxes1[:, 3])\n",
    "        w2 = torch.exp(bboxes2[:, 2])\n",
    "        h2 = torch.exp(bboxes2[:, 3])\n",
    "        area1 = w1 * h1\n",
    "        area2 = w2 * h2\n",
    "        center_x1 = bboxes1[:, 0]\n",
    "        center_y1 = bboxes1[:, 1]\n",
    "        center_x2 = bboxes2[:, 0]\n",
    "        center_y2 = bboxes2[:, 1]\n",
    "\n",
    "        inter_l = torch.max(center_x1 - w1 / 2,center_x2 - w2 / 2)\n",
    "        inter_r = torch.min(center_x1 + w1 / 2,center_x2 + w2 / 2)\n",
    "        inter_t = torch.max(center_y1 - h1 / 2,center_y2 - h2 / 2)\n",
    "        inter_b = torch.min(center_y1 + h1 / 2,center_y2 + h2 / 2)\n",
    "        inter_area = torch.clamp((inter_r - inter_l),min=0) * torch.clamp((inter_b - inter_t),min=0)\n",
    "\n",
    "        c_l = torch.min(center_x1 - w1 / 2,center_x2 - w2 / 2)\n",
    "        c_r = torch.max(center_x1 + w1 / 2,center_x2 + w2 / 2)\n",
    "        c_t = torch.min(center_y1 - h1 / 2,center_y2 - h2 / 2)\n",
    "        c_b = torch.max(center_y1 + h1 / 2,center_y2 + h2 / 2)\n",
    "\n",
    "        inter_diag = (center_x2 - center_x1)**2 + (center_y2 - center_y1)**2\n",
    "        c_diag = torch.clamp((c_r - c_l),min=0)**2 + torch.clamp((c_b - c_t),min=0)**2\n",
    "\n",
    "        union = area1+area2-inter_area\n",
    "        u = (inter_diag) / c_diag\n",
    "        iou = inter_area / union\n",
    "        v = (4 / (math.pi ** 2)) * torch.pow((torch.atan(w2 / h2) - torch.atan(w1 / h1)), 2)\n",
    "        with torch.no_grad():\n",
    "            S = (iou>0.5).float()\n",
    "            alpha= S*v/(1-iou+v)\n",
    "        cious = iou - u - alpha * v\n",
    "        cious = torch.clamp(cious,min=-1.0,max = 1.0)\n",
    "        if exchange:\n",
    "            cious = cious.T\n",
    "        return torch.sum(1-cious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-small",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eff_loc",
   "language": "python",
   "name": "eff_loc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
